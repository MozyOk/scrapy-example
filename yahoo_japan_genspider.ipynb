{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd yahoo_japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'topics' using template 'basic' in module:\n",
      "  yahoo_japan.spiders.topics\n"
     ]
    }
   ],
   "source": [
    "scrapy genspider topics yahoo.co.jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider 'topics_detail' already exists in module:\n",
      "  yahoo_japan.spiders.topics_detail\n"
     ]
    }
   ],
   "source": [
    "scrapy genspider topics_detail yahoo.co.jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created spider 'news_crawl' using template 'crawl' in module:\n",
      "  yahoo_japan.spiders.news_crawl\n"
     ]
    }
   ],
   "source": [
    "scrapy genspider -t crawl news_crawl yahoo.co.jp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\n",
      "import scrapy\n",
      "from scrapy.linkextractors import LinkExtractor\n",
      "from scrapy.spiders import CrawlSpider, Rule\n",
      "\n",
      "\n",
      "class NewsCrawlSpider(CrawlSpider):\n",
      "    name = 'news_crawl'\n",
      "    allowed_domains = ['yahoo.co.jp']\n",
      "    start_urls = ['http://yahoo.co.jp/']\n",
      "\n",
      "    rules = (\n",
      "        Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True),\n",
      "    )\n",
      "\n",
      "    def parse_item(self, response):\n",
      "        i = {}\n",
      "        #i['domain_id'] = response.xpath('//input[@id=\"sid\"]/@value').extract()\n",
      "        #i['name'] = response.xpath('//div[@id=\"name\"]').extract()\n",
      "        #i['description'] = response.xpath('//div[@id=\"description\"]').extract()\n",
      "        return i\n"
     ]
    }
   ],
   "source": [
    "cat yahoo_japan/spiders/news_crawl.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
